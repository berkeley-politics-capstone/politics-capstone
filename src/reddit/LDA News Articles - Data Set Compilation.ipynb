{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tqdm\n",
    "#initialize tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../../data/reddit/Article_data_2019/'\n",
    "useful_topics = [2,4,6,7,8,9,12,13,14,17,18,19,20,21,22,23,24,26,28,29,30,31,32,33,34,35,38,42,44,45,46,47,48,50,51,\n",
    "                 52,53,55,58,61,62,63,64,66,67,68,69,70,71,75,77,78,79,80,85,86,87,88,89,91,92,93,96,99]\n",
    "\n",
    "topic_titles = ['2020 election', 'trump administration', 'climate change', 'trump foreign policy', 'mueller report', \n",
    "                'cohen', 'williamson', '2018 congress', 'border', 'first debate', 'hunder biden', 'town hall', \n",
    "                'first debate', 'biden busing', 'female congresswomen', 'nxivm sex cult', 'auto industry', \n",
    "                'assange + stone', 'healthcare', 'de blasio', 'buttigieg', 'impeachment', \n",
    "                'us economy (socialism vs captialism)', 'economic foreign policy', 'iowa caucus', \n",
    "                'north carolina voter fraud', 'north korea', 'jean carroll', '2020 election', 'kavanaugh', \n",
    "                'harris', 'mccain', 'aoc', 'sanders', 'border', 'prison reform', 'getty', 'graham', \n",
    "                '2020 democractic party', 'stephanopoulos', 'tax fact check', 'generic words', 'o\\'rourke', \n",
    "                'media words', 'drugs', 'venezuela', 'tech', 'iran', 'assange', 'random', 'healthcare', \n",
    "                'harris', 'student debt', 'russian interference', 'politico', 'booker', 'socialism', \n",
    "                'megan davis', 'lgbtq', 'swalwell', 'former counsel for mueller report', 'trump racist', \n",
    "                'sanders', 'sanders', 'puerto rico', 'reuters', 'hickenlooper', 'tax return', 'supreme court', \n",
    "                '2020 democratic primary', 'electoral college', 'inslee', 'gravel', 'generic words', 'socialism', \n",
    "                'marijuana', 'maher', 'gun laws', 'yang', 'unions', '2020 democractic primary', 'media words', \n",
    "                'hamilton musical??', 'pundits', 'stacey abrams', 'trump', 'warren', 'israel', 'congress', 'harris', \n",
    "                'southern racism', 'civil rights', 'busing', 'north korea', 'gold', 'stufff', 'mcconnell', 'stuffs', \n",
    "                'generic words', 'iran/afghanistan']\n",
    "\n",
    "candidates = [\"SANDERS\",\"DELANEY\",\"WARREN\",\"HARRIS\",\"GILLIBRAND\",\"O'ROURKE\",\"KLOBUCHAR\",\"BOOKER\",\n",
    "    \"BUTTIGIEG\",\"GABBARD\",\"YANG\",\"INSLEE\",\"HICKENLOOPER\",\"WILLIAMSON\",\"TULSI\",\"CASTRO\",\"BIDEN\", \"BERNIE\",\n",
    "    \"BETO\", \"ROURKE\", \"BENNETT\", \"BULLOCK\", \"BLASIO\", \"TIM RYAN\", \"GRAVEL\"]\n",
    "candidates = set([x.lower() for x in candidates])\n",
    "\n",
    "candidate_dict = {'klobuchar': 'klobuchar',\n",
    " 'bennett': 'bennett',\n",
    " 'booker': 'booker',\n",
    " 'warren': 'warren',\n",
    " 'castro': 'castro',\n",
    " 'williamson': 'williamson',\n",
    " 'gabbard': 'gabbard',\n",
    " 'bernie': 'sanders',\n",
    " \"o'rourke\": \"o_rourke\",\n",
    " 'bullock': 'bullock',\n",
    " 'tim ryan': 'tim_ryan',\n",
    " 'sanders': 'sanders',\n",
    " 'biden': 'biden',\n",
    " 'hickenlooper': 'hickenlooper',\n",
    " 'blasio': 'de_blasio',\n",
    " 'yang': 'yang',\n",
    " 'delaney': 'delaney',\n",
    " 'gillibrand': 'gillibrand',\n",
    " 'beto': 'o_rourke',\n",
    " 'harris': 'harris',\n",
    " 'inslee': 'inslee',\n",
    " 'rourke': 'o_rourke',\n",
    " 'gravel': 'gravel',\n",
    " 'tulsi': 'gabbard',\n",
    " 'buttigieg': 'buttigieg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source data\n",
    "filename = DATA_DIR + 'LDA/df.pkl'\n",
    "df = pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/usr/local/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# model and corpus\n",
    "model = gensim.models.LdaModel.load(DATA_DIR + '/LDA/models/100_model_10_article_text_2019_candidate_only_len4.gensim')\n",
    "dictionary = gensim.corpora.Dictionary.load(DATA_DIR + 'LDA/article_text_2019_candidate_only_dictionary.gensim')\n",
    "corpus = pickle.load(open(DATA_DIR + 'LDA/article_text_2019_candidate_only' + '_corpus.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bf173ab31143468ffeaa26f070a51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78409), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d7a03c79384aefae858b7e79a8dc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78409), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['corpus'] = df.text_lemmas.progress_map(lambda x: dictionary.doc2bow(x))\n",
    "df['topics'] = df.corpus.progress_map(lambda x: list(filter(lambda y: y[0] in useful_topics,model[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705f9d28d5d74db48920cb8592afcb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78409), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def vector_concatenator(vector):\n",
    "    v = [(topic_titles[y[0]], y[1]) for y in vector]\n",
    "    v_final = dict()\n",
    "    for t in v:\n",
    "        if t[0] in v_final.keys():\n",
    "            v_final[t[0]] += t[1]\n",
    "        else:\n",
    "            v_final[t[0]] = t[1]\n",
    "    return list(zip(v_final.keys(), v_final.values()))\n",
    "\n",
    "df['topic_titles'] = df.topics.progress_map(vector_concatenator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c349543df9e54dc1b0df8a9a2a935a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78409), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929c9bd3fcf447839567f204c9cf8f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=78409), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def intersection(lemma): \n",
    "    lemma = [token.lower() for token in lemma]\n",
    "    intersect = candidates.intersection(lemma)\n",
    "    return {candidate_dict[x] for x in intersect}\n",
    "\n",
    "df['candidate_title'] = df['title_lemmas'].progress_map(intersection)\n",
    "df['candidate_text'] = df['text_lemmas'].progress_map(intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_DIR + 'final_top_topics_news_articles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated in Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get date dataframes\n",
    "df_date = pd.read_pickle(DATA_DIR + 'reddit_2019jun16tojul1_dates.pkl')\n",
    "df_date = df_date.append(pd.read_pickle(DATA_DIR + 'reddit_2019_dates.pkl'))\n",
    "df_date = df_date.append(pd.read_csv(DATA_DIR + 'dates_missing_ids.csv', index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.merge(df_date, on='id', how='left') #df.join(df_date, on='id', how='left')\n",
    "df2['day'] = pd.to_datetime(df2['created_utc'], yearfirst=True).dt.round('d')\n",
    "df2['candidate_text'] = df2.candidate_text.map(lambda x: list(x))\n",
    "df2['counter'] = 1\n",
    "df2.counter = df2.counter.astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_concatenator(row):\n",
    "    vector = row.topic_titles\n",
    "    v_final = dict()\n",
    "    for t in vector:\n",
    "        if t[0] in v_final.keys():\n",
    "            v_final[t[0]] += t[1]\n",
    "        else:\n",
    "            v_final[t[0]] = t[1]\n",
    "    return list(zip(v_final.keys(), map(lambda x: x/row.counter, v_final.values())))\n",
    "\n",
    "def vector_counter(row):\n",
    "    vector = row.candidate_text\n",
    "    v_final = dict()\n",
    "    for t in vector:\n",
    "        if t in v_final.keys():\n",
    "            v_final[t] += 1\n",
    "        else:\n",
    "            v_final[t] = 1\n",
    "    return list(zip(v_final.keys(), map(lambda x: x/row.counter, v_final.values())))\n",
    "\n",
    "def normalize_topics(row):\n",
    "    tt = row.topic_titles.copy()\n",
    "    s = 0\n",
    "    for x in tt:\n",
    "        s += x[1]\n",
    "        \n",
    "    for i in range(len(tt)):\n",
    "        tt[i] = (tt[i][0], tt[i][1]*(1.0/s))\n",
    "        \n",
    "    return tt\n",
    "\n",
    "candidate_dfs = dict()\n",
    "for candidate in set(candidate_dict.values()):\n",
    "    candidate_dfs[candidate] = df2[df2.candidate_text.map(lambda x: candidate in x)]\\\n",
    "                                [['counter', 'score', 'candidate_text', 'topic_titles','day']]\\\n",
    "                                .groupby('day').agg(sum)\n",
    "    candidate_dfs[candidate].topic_titles = candidate_dfs[candidate].apply(vector_concatenator, axis=1)\n",
    "    candidate_dfs[candidate].candidate_text = candidate_dfs[candidate].apply(vector_counter, axis=1)\n",
    "    candidate_dfs[candidate].topic_titles = candidate_dfs[candidate].apply(normalize_topics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../../data/reddit/Article_data_2019/candidate_aggregation/: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir {DATA_DIR + 'candidate_aggregation/'}\n",
    "for candidate in set(candidate_dict.values()):\n",
    "    candidate_dfs[candidate].to_csv(DATA_DIR + 'candidate_aggregation/' + candidate + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('first debate', 0.025658442230806204),\n",
       " ('sanders', 0.12106575735380976),\n",
       " (\"o'rourke\", 0.00997618037889153),\n",
       " ('tech', 0.012727913236780393),\n",
       " ('assange', 0.0015186678095882476),\n",
       " ('healthcare', 0.09580821438594371),\n",
       " ('2020 democratic primary', 0.01164144028923045),\n",
       " ('trump', 0.007296036235960234),\n",
       " ('harris', 0.07515869516681667),\n",
       " ('civil rights', 0.02431009758770042),\n",
       " ('climate change', 0.09689594971142895),\n",
       " ('2018 congress', 0.04451531920373167),\n",
       " ('aoc', 0.010611854272047413),\n",
       " ('border', 0.01394964301242738),\n",
       " ('economic foreign policy', 0.0032955526178973294),\n",
       " ('kavanaugh', 0.015168810119879413),\n",
       " ('mccain', 0.018358680340484972),\n",
       " ('supreme court', 0.016149511781106827),\n",
       " ('congress', 0.060144394163205064),\n",
       " ('2020 democractic party', 0.03043741572403697),\n",
       " ('iran', 0.002539798609946921),\n",
       " ('marijuana', 0.07148023242772159),\n",
       " ('gun laws', 0.0015381450100615947),\n",
       " ('unions', 0.001843690166288994),\n",
       " ('warren', 0.010924470076767136),\n",
       " ('mueller report', 0.0011981443393503097),\n",
       " ('2020 election', 0.050558334675905134),\n",
       " ('prison reform', 0.014341456638068581),\n",
       " ('booker', 0.005320117616564274),\n",
       " ('trump racist', 0.03739508139115104),\n",
       " ('electoral college', 0.019965296032990233),\n",
       " ('williamson', 0.006652046735552784),\n",
       " ('de blasio', 0.0009333922037186751),\n",
       " ('2020 democractic primary', 0.008768565259136399),\n",
       " ('us economy (socialism vs captialism)', 0.014495256691405192),\n",
       " ('student debt', 0.04034176249484875),\n",
       " ('hickenlooper', 0.0020900745492633908),\n",
       " ('female congresswomen', 0.0013331784325417689),\n",
       " ('north korea', 0.008957454705650255),\n",
       " ('israel', 0.0027223592599369276),\n",
       " ('mcconnell', 0.001046901446675053),\n",
       " ('iran/afghanistan', 0.0008656656146815745)]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_dfs['harris'].topic_titles[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [('first debate', 0.025658442230806204),\n",
    " ('sanders', 0.12106575735380976),\n",
    " (\"o'rourke\", 0.00997618037889153),\n",
    " ('tech', 0.012727913236780393),\n",
    " ('assange', 0.0015186678095882476),\n",
    " ('healthcare', 0.09580821438594371),\n",
    " ('2020 democratic primary', 0.01164144028923045),\n",
    " ('trump', 0.007296036235960234),\n",
    " ('harris', 0.07515869516681667),\n",
    " ('civil rights', 0.02431009758770042),\n",
    " ('climate change', 0.09689594971142895),\n",
    " ('2018 congress', 0.04451531920373167),\n",
    " ('aoc', 0.010611854272047413),\n",
    " ('border', 0.01394964301242738),\n",
    " ('economic foreign policy', 0.0032955526178973294),\n",
    " ('kavanaugh', 0.015168810119879413),\n",
    " ('mccain', 0.018358680340484972),\n",
    " ('supreme court', 0.016149511781106827),\n",
    " ('congress', 0.060144394163205064),\n",
    " ('2020 democractic party', 0.03043741572403697),\n",
    " ('iran', 0.002539798609946921),\n",
    " ('marijuana', 0.07148023242772159),\n",
    " ('gun laws', 0.0015381450100615947),\n",
    " ('unions', 0.001843690166288994),\n",
    " ('warren', 0.010924470076767136),\n",
    " ('mueller report', 0.0011981443393503097),\n",
    " ('2020 election', 0.050558334675905134),\n",
    " ('prison reform', 0.014341456638068581),\n",
    " ('booker', 0.005320117616564274),\n",
    " ('trump racist', 0.03739508139115104),\n",
    " ('electoral college', 0.019965296032990233),\n",
    " ('williamson', 0.006652046735552784),\n",
    " ('de blasio', 0.0009333922037186751),\n",
    " ('2020 democractic primary', 0.008768565259136399),\n",
    " ('us economy (socialism vs captialism)', 0.014495256691405192),\n",
    " ('student debt', 0.04034176249484875),\n",
    " ('hickenlooper', 0.0020900745492633908),\n",
    " ('female congresswomen', 0.0013331784325417689),\n",
    " ('north korea', 0.008957454705650255),\n",
    " ('israel', 0.0027223592599369276),\n",
    " ('mcconnell', 0.001046901446675053),\n",
    " ('iran/afghanistan', 0.0008656656146815745)]\n",
    "\n",
    "s = 0\n",
    "for x in l:\n",
    "    s += x[1]\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
