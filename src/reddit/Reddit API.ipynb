{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Reddit PRAW and Pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import requests\n",
    "import praw\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "from datetime import datetime, timedelta, date\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following cells uses an INI file to pull in credentials needed to access the PRAW API.\n",
    "# This INI file is stored locally only\n",
    "\n",
    "config = configparser.RawConfigParser()\n",
    "config.read(\"config.txt\")\n",
    "reddit = praw.Reddit(client_id=config.get(\"reddit\",\"client_id\"),\n",
    "                     client_secret=config.get(\"reddit\",\"client_secret\"),\n",
    "                     password=config.get(\"reddit\",\"password\"),\n",
    "                     user_agent=\"Political exploration\",\n",
    "                     username=config.get(\"reddit\",\"username\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Data\n",
    "\n",
    "The API can look at a subreddit and pull information like the title, url, and body of a post (if it's not a link post).\n",
    "We can also get the karma score, the number of comments, and when the post was created.\n",
    "\n",
    "We'll generally want to look at /r/politics, /r/news, and /r/worldnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are the majority-makers in Congress. Meet t...</td>\n",
       "      <td>1394</td>\n",
       "      <td>bugtra</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/bug...</td>\n",
       "      <td>1177</td>\n",
       "      <td>The New Democrat Coalition is a group of 101 f...</td>\n",
       "      <td>2019-05-30 00:30:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conservatives Stunned by Mueller Suggesting Tr...</td>\n",
       "      <td>25462</td>\n",
       "      <td>butf0t</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://nymag.com/intelligencer/2019/05/conser...</td>\n",
       "      <td>2737</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 21:51:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump says Russia 'helped me get elected' for ...</td>\n",
       "      <td>63781</td>\n",
       "      <td>buscyw</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.independent.co.uk/news/world/ameri...</td>\n",
       "      <td>6690</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 20:08:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Finally Admits Russia Helped Him Get Ele...</td>\n",
       "      <td>9102</td>\n",
       "      <td>busa98</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.thedailybeast.com/trump-finally-ad...</td>\n",
       "      <td>430</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 20:00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sen. Elizabeth Warren on The View: If Trump we...</td>\n",
       "      <td>3353</td>\n",
       "      <td>buuqoh</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://abcnews.go.com/Politics/sen-elizabeth-...</td>\n",
       "      <td>268</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 23:46:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The USS John McCain Debacle Shows the Whole Co...</td>\n",
       "      <td>4718</td>\n",
       "      <td>butiti</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.esquire.com/news-politics/politics...</td>\n",
       "      <td>333</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 22:00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fox News's Shep Smith: Mueller statement 'dire...</td>\n",
       "      <td>9584</td>\n",
       "      <td>burvdr</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://thehill.com/homenews/media/446033-fox-...</td>\n",
       "      <td>403</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 19:12:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trump Attacks Mueller Probe - Inadvertently Co...</td>\n",
       "      <td>6820</td>\n",
       "      <td>busfjn</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.haaretz.com/us-news/trump-attacks-...</td>\n",
       "      <td>312</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 20:16:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Republican group to hand-deliver Mueller repor...</td>\n",
       "      <td>3277</td>\n",
       "      <td>buufm0</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://thehill.com/homenews/house/446140-repu...</td>\n",
       "      <td>171</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 23:20:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sun-Maid Pulls Baseball Sponsorship After Team...</td>\n",
       "      <td>7207</td>\n",
       "      <td>bus1mi</td>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.newsweek.com/sun-maid-alexandria-o...</td>\n",
       "      <td>778</td>\n",
       "      <td></td>\n",
       "      <td>2019-05-30 19:33:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id subreddit  \\\n",
       "0  We are the majority-makers in Congress. Meet t...   1394  bugtra  politics   \n",
       "1  Conservatives Stunned by Mueller Suggesting Tr...  25462  butf0t  politics   \n",
       "2  Trump says Russia 'helped me get elected' for ...  63781  buscyw  politics   \n",
       "3  Trump Finally Admits Russia Helped Him Get Ele...   9102  busa98  politics   \n",
       "4  Sen. Elizabeth Warren on The View: If Trump we...   3353  buuqoh  politics   \n",
       "5  The USS John McCain Debacle Shows the Whole Co...   4718  butiti  politics   \n",
       "6  Fox News's Shep Smith: Mueller statement 'dire...   9584  burvdr  politics   \n",
       "7  Trump Attacks Mueller Probe - Inadvertently Co...   6820  busfjn  politics   \n",
       "8  Republican group to hand-deliver Mueller repor...   3277  buufm0  politics   \n",
       "9  Sun-Maid Pulls Baseball Sponsorship After Team...   7207  bus1mi  politics   \n",
       "\n",
       "                                                 url  num_comments  \\\n",
       "0  https://www.reddit.com/r/politics/comments/bug...          1177   \n",
       "1  https://nymag.com/intelligencer/2019/05/conser...          2737   \n",
       "2  https://www.independent.co.uk/news/world/ameri...          6690   \n",
       "3  https://www.thedailybeast.com/trump-finally-ad...           430   \n",
       "4  https://abcnews.go.com/Politics/sen-elizabeth-...           268   \n",
       "5  https://www.esquire.com/news-politics/politics...           333   \n",
       "6  https://thehill.com/homenews/media/446033-fox-...           403   \n",
       "7  https://www.haaretz.com/us-news/trump-attacks-...           312   \n",
       "8  https://thehill.com/homenews/house/446140-repu...           171   \n",
       "9  https://www.newsweek.com/sun-maid-alexandria-o...           778   \n",
       "\n",
       "                                                body             created  \n",
       "0  The New Democrat Coalition is a group of 101 f... 2019-05-30 00:30:20  \n",
       "1                                                    2019-05-30 21:51:12  \n",
       "2                                                    2019-05-30 20:08:47  \n",
       "3                                                    2019-05-30 20:00:59  \n",
       "4                                                    2019-05-30 23:46:59  \n",
       "5                                                    2019-05-30 22:00:38  \n",
       "6                                                    2019-05-30 19:12:51  \n",
       "7                                                    2019-05-30 20:16:01  \n",
       "8                                                    2019-05-30 23:20:04  \n",
       "9                                                    2019-05-30 19:33:01  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data pull\n",
    "\n",
    "posts = []\n",
    "\n",
    "for post in reddit.subreddit('politics').hot(limit=10):\n",
    "    posts.append([post.title, \n",
    "                  post.score, \n",
    "                  post.id, \n",
    "                  post.subreddit, \n",
    "                  post.url, \n",
    "                  post.num_comments, \n",
    "                  post.selftext, \n",
    "                  datetime.utcfromtimestamp(post.created)\n",
    "                 ])\n",
    "df = pd.DataFrame(posts,\n",
    "                     columns=['title', \n",
    "                              'score', \n",
    "                              'id', \n",
    "                              'subreddit', \n",
    "                              'url', \n",
    "                              'num_comments', \n",
    "                              'body', \n",
    "                              'created'\n",
    "                             ])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of URLs\n",
    "\n",
    "To grab text articles from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>politics</td>\n",
       "      <td>http://nymag.com/intelligencer/2019/05/study-t...</td>\n",
       "      <td>2019-06-02 23:53:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.newsweek.com/support-trump-impeach...</td>\n",
       "      <td>2019-06-03 00:07:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://thehill.com/homenews/administration/44...</td>\n",
       "      <td>2019-06-02 21:10:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.cnn.com/2019/05/31/politics/elizab...</td>\n",
       "      <td>2019-06-02 20:52:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.rollingstone.com/politics/politics...</td>\n",
       "      <td>2019-06-03 00:43:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://thehill.com/homenews/sunday-talk-shows...</td>\n",
       "      <td>2019-06-02 23:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.motherjones.com/politics/2019/06/p...</td>\n",
       "      <td>2019-06-03 00:59:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.axios.com/trump-mexico-tariffs-tax...</td>\n",
       "      <td>2019-06-03 02:57:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://www.independent.co.uk/news/world/ameri...</td>\n",
       "      <td>2019-06-02 20:51:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>politics</td>\n",
       "      <td>https://abcnews.go.com/International/wireStory...</td>\n",
       "      <td>2019-06-02 18:29:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                                url  \\\n",
       "0  politics  http://nymag.com/intelligencer/2019/05/study-t...   \n",
       "1  politics  https://www.newsweek.com/support-trump-impeach...   \n",
       "2  politics  https://thehill.com/homenews/administration/44...   \n",
       "3  politics  https://www.cnn.com/2019/05/31/politics/elizab...   \n",
       "4  politics  https://www.rollingstone.com/politics/politics...   \n",
       "5  politics  https://thehill.com/homenews/sunday-talk-shows...   \n",
       "6  politics  https://www.motherjones.com/politics/2019/06/p...   \n",
       "7  politics  https://www.axios.com/trump-mexico-tariffs-tax...   \n",
       "8  politics  https://www.independent.co.uk/news/world/ameri...   \n",
       "9  politics  https://abcnews.go.com/International/wireStory...   \n",
       "\n",
       "              created  \n",
       "0 2019-06-02 23:53:58  \n",
       "1 2019-06-03 00:07:05  \n",
       "2 2019-06-02 21:10:35  \n",
       "3 2019-06-02 20:52:29  \n",
       "4 2019-06-03 00:43:11  \n",
       "5 2019-06-02 23:50:00  \n",
       "6 2019-06-03 00:59:57  \n",
       "7 2019-06-03 02:57:48  \n",
       "8 2019-06-02 20:51:38  \n",
       "9 2019-06-02 18:29:53  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data pull\n",
    "\n",
    "urls = []\n",
    "\n",
    "for post in reddit.subreddit('politics').hot(limit=10):\n",
    "    urls.append([post.subreddit, \n",
    "                  post.url,\n",
    "                  datetime.utcfromtimestamp(post.created)\n",
    "                 ])\n",
    "df = pd.DataFrame(urls,columns=['subreddit','url','created'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrowing down the data\n",
    "\n",
    "### By Subreddit\n",
    "\n",
    "Michael Bennet, Steve Bullock, Juli√°n Castro, Bill de Blasio, John Delaney, John Hickenlooper, Seth Moulton, Tim Ryan, Eric Swalwell, Marianne Williamson, and Andrew Yang are candidates who do not have dedicated subreddits as of May 30, 2019.\n",
    "\n",
    "For the other candidates, here are their subscriber counts as of May 30, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JoeBiden :  952\n",
      "corybooker :  378\n",
      "Pete_Buttigieg :  22156\n",
      "tulsi :  10607\n",
      "Kirsten_Gillibrand :  106\n",
      "gravelforpresident :  3660\n",
      "Kamala :  1617\n",
      "inslee2020 :  546\n",
      "BaemyKlobaechar :  502\n",
      "Beto2020 :  10131\n",
      "SandersForPresident :  249726\n",
      "The_Donald :  747188\n",
      "ElizabethWarren :  11381\n",
      "politics :  5120363\n"
     ]
    }
   ],
   "source": [
    "subreddits = {'Joe Biden': 'JoeBiden',\n",
    "              'Cory Booker': 'corybooker',\n",
    "              'Pete Buttigieg': 'Pete_Buttigieg',\n",
    "              'Tulsi Gabbard': 'tulsi',\n",
    "              'Kirsten Gillibrand': 'Kirsten_Gillibrand',\n",
    "              'Mike Gravel': 'gravelforpresident',\n",
    "              'Kamala Harris': 'Kamala',\n",
    "              'Jay Inslee': 'inslee2020',\n",
    "              'Amy Klobuchar': 'BaemyKlobaechar',\n",
    "              'Beto O\\'Rourke': 'Beto2020',\n",
    "              'Bernie Sanders': 'SandersForPresident',\n",
    "              'Donald Trump': 'The_Donald',\n",
    "              'Elizabeth Warren': 'ElizabethWarren',\n",
    "              'politics': 'politics'}\n",
    "\n",
    "for subreddit in subreddits.values():\n",
    "    print(subreddit,': ',reddit.subreddit(subreddit).subscribers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Date\n",
    "\n",
    "To narrow down by date, we can either use the `reddit.subreddit('subreddit').search` functionality, or make the call with conditions set around the `post.created` parameter.\n",
    "\n",
    "## Feature Engineering\n",
    "\n",
    "Possible ideas include:\n",
    "\n",
    "1. Number of average and cumulative posts in a subreddit, but the API doesn't make this easy to get.\n",
    "2. The karma/score and number of comments for an associated headline.\n",
    "3. Topic modeling on the headline\n",
    "4. What candidate is addressed in the headline\n",
    "5. Sentiment analysis on the headline\n",
    "6. Counting if the word \"donation\" is referenced in the headline (better yet, the comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Megathread: Robert Mueller to Make Public Statement About Russia Investigation'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using id = buf84a as a test\n",
    "\n",
    "sample_post = reddit.submission(id='buf84a')\n",
    "\n",
    "sample_post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This runs too long\n",
    "\n",
    "sample_post.comments.replace_more(limit=None)\n",
    "\n",
    "for top_level_comment in sample_post.comments:\n",
    "    #print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Will be switching over to Pushshift API for this process, which allows us to get data between dates\n",
    "\n",
    "Example call: https://api.pushshift.io/reddit/submission/search/?after=2019-06-02&before=2019-06-03&q=trump&sort_type=score&sort=desc&subreddit=politics&limit=500\n",
    "\n",
    "Where the output is a JSON file, the after date is the date of interest, and the before date is one date in the future.\n",
    "\n",
    "### Headline compared to donations\n",
    "#### Consider calculating the cumulative karma score and comments along with this later on\n",
    "\n",
    "The Pushshift API call used here will rely on `agg=subreddit` to get counts and will look like the following:\n",
    "\n",
    "https://api.pushshift.io/reddit/submission/search/?subreddit=politics,news,worldnews&aggs=subreddit&q=trump&size=0&after=2019-06-02&before=2019-06-03\n",
    "\n",
    "This data will be stored in a csv file that can be pulled in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate</th>\n",
       "      <th>date</th>\n",
       "      <th>doc_count</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>harris</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>9</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>harris</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>11</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>harris</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buttigieg</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>4</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yang</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yang</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>3</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gillibrand</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>delaney</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hickenlooper</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>7</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>warren</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>9</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>warren</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sanders</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>18</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sanders</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>4</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sanders</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>booker</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>4</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>booker</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>trump</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>174</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trump</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>76</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trump</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>19</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>biden</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>28</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>biden</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>5</td>\n",
       "      <td>worldnews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>biden</td>\n",
       "      <td>2019-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       candidate        date  doc_count  subreddit\n",
       "0         harris  2019-06-02          9   politics\n",
       "1         harris  2019-06-02         11  worldnews\n",
       "2         harris  2019-06-02          2       news\n",
       "3      buttigieg  2019-06-02          4   politics\n",
       "4           yang  2019-06-02          1  worldnews\n",
       "5           yang  2019-06-02          3       news\n",
       "6     gillibrand  2019-06-02          1       news\n",
       "7        delaney  2019-06-02          2   politics\n",
       "8   hickenlooper  2019-06-02          7   politics\n",
       "9         warren  2019-06-02          9   politics\n",
       "10        warren  2019-06-02          1  worldnews\n",
       "11       sanders  2019-06-02         18   politics\n",
       "12       sanders  2019-06-02          4  worldnews\n",
       "13       sanders  2019-06-02          2       news\n",
       "14        booker  2019-06-02          4   politics\n",
       "15        booker  2019-06-02          1  worldnews\n",
       "16         trump  2019-06-02        174   politics\n",
       "17         trump  2019-06-02         76  worldnews\n",
       "18         trump  2019-06-02         19       news\n",
       "19         biden  2019-06-02         28   politics\n",
       "20         biden  2019-06-02          5  worldnews\n",
       "21         biden  2019-06-02          1       news"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#day_count = (date(2019, 6, 3) - date(2019, 6, 1)).days + 1\n",
    "#for single_date in (start_date + timedelta(n) for n in range(day_count)):\n",
    "#    print(single_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "afterDate = '2019-06-02'\n",
    "beforeDate = '2019-06-03'\n",
    "\n",
    "# Dates above means it will capture data for June 2\n",
    "politicians = ['williamson', 'harris', 'buttigieg', 'klobuchar', 'yang', 'gillibrand', 'delaney', 'inslee', \n",
    "               'hickenlooper', 'orourke', 'warren', 'castro', 'sanders', 'gabbard', 'booker', 'trump', 'biden']\n",
    "\n",
    "for candidate in politicians:\n",
    "    dict1 = {}\n",
    "    dict2 = {}\n",
    "    dict3 = {}\n",
    "    url = \"https://api.pushshift.io/reddit/submission/search/?subreddit=politics&aggs=subreddit&q={0}&size=0&after={1}&before={2}\".format(candidate,afterDate,beforeDate)\n",
    "    response = requests.get(url).json()\n",
    "    if response['aggs']['subreddit']:\n",
    "        dict1.update({'date': afterDate, 'candidate': candidate, 'subreddit': 'politics', 'doc_count': response['aggs']['subreddit'][0]['doc_count']}) \n",
    "        rows_list.append(dict1)\n",
    "    \n",
    "    url = \"https://api.pushshift.io/reddit/submission/search/?subreddit=worldnews&aggs=subreddit&q={0}&size=0&after={1}&before={2}\".format(candidate,afterDate,beforeDate)\n",
    "    response = requests.get(url).json()\n",
    "    if response['aggs']['subreddit']:\n",
    "        dict2.update({'date': afterDate, 'candidate': candidate, 'subreddit': 'worldnews', 'doc_count': response['aggs']['subreddit'][0]['doc_count']}) \n",
    "        rows_list.append(dict2)\n",
    "    \n",
    "    url = \"https://api.pushshift.io/reddit/submission/search/?subreddit=news&aggs=subreddit&q={0}&size=0&after={1}&before={2}\".format(candidate,afterDate,beforeDate)\n",
    "    response = requests.get(url).json()\n",
    "    if response['aggs']['subreddit']:\n",
    "        dict3.update({'date': afterDate, 'candidate': candidate, 'subreddit': 'news', 'doc_count': response['aggs']['subreddit'][0]['doc_count']}) \n",
    "        rows_list.append(dict3)\n",
    "    \n",
    "mentions = pd.DataFrame(rows_list)\n",
    "\n",
    "mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0, 'headline': 'We are the majority-makers in Congress. Meet the New Dems! A(us)A'}\n",
      "{'neg': 0.13, 'neu': 0.648, 'pos': 0.222, 'compound': 0.25, 'headline': 'Conservatives Stunned by Mueller Suggesting Trump Is Not Innocent'}\n",
      "{'neg': 0.209, 'neu': 0.791, 'pos': 0.0, 'compound': -0.5719, 'headline': \"Trump says Russia 'helped me get elected' for first time in furious outburst at Mueller\"}\n",
      "{'neg': 0.0, 'neu': 0.761, 'pos': 0.239, 'compound': 0.296, 'headline': 'Trump Finally Admits Russia Helped Him Get Elected'}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0, 'headline': \"Sen. Elizabeth Warren on The View: If Trump weren't president 'he'd be in handcuffs'\"}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0, 'headline': 'The USS John McCain Debacle Shows the Whole Country Has to Cater to President* Snowflake'}\n",
      "{'neg': 0.204, 'neu': 0.796, 'pos': 0.0, 'compound': -0.3182, 'headline': \"Fox News's Shep Smith: Mueller statement 'directly contradicted' Trump administration\"}\n",
      "{'neg': 0.244, 'neu': 0.756, 'pos': 0.0, 'compound': -0.4404, 'headline': 'Trump Attacks Mueller Probe - Inadvertently Confirms Russia Helped Elect Him'}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0, 'headline': 'Republican group to hand-deliver Mueller report to every GOP lawmaker'}\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0, 'headline': 'Sun-Maid Pulls Baseball Sponsorship After Team Airs Memorial Day Montage Likening Alexandria Ocasio-Cortez to Kim Jong Un, Fidel Castro'}\n"
     ]
    }
   ],
   "source": [
    "sia = SIA()\n",
    "results = []\n",
    "\n",
    "for i in range(0,len(posts)):\n",
    "    line = posts[i][0]\n",
    "    pol_score = sia.polarity_scores(line)\n",
    "    pol_score['headline'] = line\n",
    "    #results.append(pol_score)\n",
    "    print(pol_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to a csv file if needed for the future\n",
    "\n",
    "posts.to_csv('reddit_posts.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
